# -*- coding: utf-8 -*-
"""Módulo de Refinamento Cruzado (Corrigido)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fvzFk5nFc4hLyGjIIwqdCQB36KsVwW-u
"""

# =============================================================================
# File: app/refine.py
# Version: 2025-09-14 21:45:00 -03 (America/Sao_Paulo)
# Description: Módulo responsável pela lógica de refinamento cruzado.
#              Cada IA recebe a sua resposta e a do oponente para melhoria.
# =============================================================================
from __future__ import annotations
import asyncio
from typing import Dict, Any, Tuple

from app.observability import logger
from app.openai_client import ask_openai as ask_openai_async
from app.gemini_client import ask_gemini as ask_gemini_async

REFINE_PROMPT = """Tarefa: Melhore a sua resposta inicial considerando a resposta de outro modelo como referência.
O seu objetivo é: corrigir imprecisões, cobrir lacunas que o outro modelo abordou, simplificar redundâncias e manter um tom consistente e claro.
Se não houver melhorias claras a fazer, retorne a sua resposta inicial sem alterações.

PERGUNTA ORIGINAL DO UTILIZADOR:
{question}

A SUA RESPOSTA INICIAL:
{your_answer}

RESPOSTA DO OUTRO MODELO (para referência):
{peer_answer}

Retorne APENAS o texto final melhorado (sem comentários, sem markdown extra, apenas a resposta)."""


async def _get_refined_answer(provider_name: str, question: str, your_answer: str, peer_answer: str) -> str:
    """Chama uma IA específica com o prompt de refinamento."""
    prompt = REFINE_PROMPT.format(
        question=question,
        your_answer=your_answer,
        peer_answer=peer_answer
    )
    try:
        if provider_name == "openai":
            response = await ask_openai_async(prompt)
        elif provider_name == "gemini":
            response = await ask_gemini_async(prompt)
        else:
            return your_answer # Retorna o original em caso de erro

        return response.get("answer", your_answer).strip()
    except Exception as e:
        logger.error(f"refine.{provider_name}.failed", error=str(e))
        return your_answer # Em caso de erro, retorna a resposta original


async def refine_answers(question: str, openai_answer: str, gemini_answer: str) -> Tuple[str, str]:
    """
    Orquestra o refinamento cruzado em paralelo.

    Retorna:
        Uma tupla com (resposta_refinada_openai, resposta_refinada_gemini)
    """
    logger.info("refine.start")

    # Prepara as duas tarefas de refinamento para serem executadas em paralelo
    openai_refine_task = _get_refined_answer(
        provider_name="openai",
        question=question,
        your_answer=openai_answer,
        peer_answer=gemini_answer
    )
    gemini_refine_task = _get_refined_answer(
        provider_name="gemini",
        question=question,
        your_answer=gemini_answer,
        peer_answer=openai_answer
    )

    # Executa em paralelo e aguarda os resultados
    refined_openai, refined_gemini = await asyncio.gather(
        openai_refine_task,
        gemini_refine_task
    )

    logger.info("refine.end")
    return refined_openai, refined_gemini

"""#### **Passo 2: Reconstrua e Execute o Docker**

Agora que o ficheiro local está corrigido, precisamos de "tirar uma nova fotografia".

1.  **Reconstrua a imagem:**
    ```bash
    docker build -t orquestrador-ai .
    ```
2.  **Execute o container:**
    ```bash
    docker run --rm -p 8000:8000 --env-file .env orquestrador-ai
    


  ```
"""